{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "Course:  DS 5100\n",
    "Module:  04 Functions HW\n",
    "Title:   Fighting Forest Fires with Functions\n",
    "Author:  R.C. Alvarado (adapted)\n",
    "Datae:   7 July 2023\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Info\n",
    "\n",
    "* Name: Chris van Niekerk\n",
    "* Net ID: mdp8gd\n",
    "* URL of this file in GitHub:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "In your **private course repo on Rivanna**, write a Jupyter notebook running Python that performs the numbered tasks below. \n",
    "\n",
    "For each task, create one or more code cells to perform the task.\n",
    "\n",
    "Save your notebook in the `M04` directory as `hw04.ipynb`. \n",
    "\n",
    "Add and commit these files to your repo. \n",
    "\n",
    "Then push your commits to your repo on GitHib.\n",
    "\n",
    "Be sure to fill out the **Student Info** block above.\n",
    "\n",
    "To submit your homework, save the notebook as a PDF and upload it to GradeScope, following the instructions.\n",
    "\n",
    "**TOTAL POINTS: 14**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this homework, you will work with the [Forest Fires Data Set from UCI](https://archive.ics.uci.edu/ml/datasets/Forest+Fires). \n",
    "\n",
    "There is a local copy of these data as a CSV file in the `HW` directory for this module in the course repo.\n",
    "\n",
    "You will create a group of related functions to process these data.\n",
    "\n",
    "This notebook will set the table for you by importing and structuring the data first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting Up\n",
    "\n",
    "First, we read in our local copy of the dataset and save it as a list of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open('uci_mldb_forestfires.csv', 'r').readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we inspect first ten lines, replacing commas with tabs for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\tY\tmonth\tday\tFFMC\tDMC\tDC\tISI\ttemp\tRH\twind\train\tarea\n",
      "7\t5\tmar\tfri\t86.2\t26.2\t94.3\t5.1\t8.2\t51\t6.7\t0\t0\n",
      "7\t4\toct\ttue\t90.6\t35.4\t669.1\t6.7\t18\t33\t0.9\t0\t0\n",
      "7\t4\toct\tsat\t90.6\t43.7\t686.9\t6.7\t14.6\t33\t1.3\t0\t0\n",
      "8\t6\tmar\tfri\t91.7\t33.3\t77.5\t9\t8.3\t97\t4\t0.2\t0\n",
      "8\t6\tmar\tsun\t89.3\t51.3\t102.2\t9.6\t11.4\t99\t1.8\t0\t0\n",
      "8\t6\taug\tsun\t92.3\t85.3\t488\t14.7\t22.2\t29\t5.4\t0\t0\n",
      "8\t6\taug\tmon\t92.3\t88.9\t495.6\t8.5\t24.1\t27\t3.1\t0\t0\n",
      "8\t6\taug\tmon\t91.5\t145.4\t608.2\t10.7\t8\t86\t2.2\t0\t0\n",
      "8\t6\tsep\ttue\t91\t129.5\t692.6\t7\t13.1\t63\t5.4\t0\t0\n"
     ]
    }
   ],
   "source": [
    "for row in data_file[:10]:\n",
    "    row = row.replace(',', '\\t')\n",
    "    print(row, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CSV into Datafame-like Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a helper function to convert the data into the form of a dataframe-like dictionary. \n",
    "\n",
    "That is, we convert a list of rows into a dictionary of columns, each cast to the appropriate data type.\n",
    "\n",
    "Later, we will use Pandas and R dataframes to do this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the data types by inspecting the data and creating a dictionary of lambda functions to do our casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = ['i', 'i', 's', 's', 'f', 'f', 'f', 'f', 'f', 'i', 'f', 'f', 'f']\n",
    "# dtypes = list(\"iissfffffifff\") # We could have done it this way, too\n",
    "\n",
    "caster = {\n",
    "    'i': lambda x: int(x),\n",
    "    's': lambda x: str(x),\n",
    "    'f': lambda x: float(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we grab the column names from the first row or list.\n",
    "\n",
    "Note that `.strip()` is a string function that removes extra whitespace from before and after a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_file[0].strip().split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we iterate through the list of rows and flip them into a dictionary of columns.\n",
    "\n",
    "The key of each dictionary element is the columns name, and the value is a list of values with a common data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows, but not the first, and convert them into lists\n",
    "rows = [line.strip().split(',') for line in data_file[1:]]\n",
    "\n",
    "# Initialize the dataframe by defining a dictionary of lists, with each column name as a key\n",
    "firedata = {col:[] for col in cols}\n",
    "\n",
    "# Iterate through the rows and convert them to columns \n",
    "for row in rows:\n",
    "    for j, col in enumerate(row):\n",
    "        firedata[cols[j]].append(caster[dtypes[j]](col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Test to see if it worked ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 4, 6, 6]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firedata['Y'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with spatial coordinates `X`, `Y`\n",
    "\n",
    "For the first tasks, we grab the first two columns of our table, which define the spatial coordinates within \n",
    "the Monteshino park map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = firedata['X'], firedata['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([7, 7, 7, 8, 8, 8, 8, 8, 8, 7], [5, 4, 4, 6, 6, 6, 6, 6, 6, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10], Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "(2 points)\n",
    "\n",
    "Write a function called `coord_builder()` with these requirements:\n",
    "\n",
    "- Takes two lists, X and Y, as inputs. X and Y must be of equal length.\n",
    "- Returns a list of tuples `[(x1,y1), (x2,y2), ..., (xn,yn)]` where `(xi,yi)` are the ordered pairs from X and Y.\n",
    "- Uses the `zip()` function to create the returned list.\n",
    "- Use a list comprehension to actually build the returned list.\n",
    "- Contains a docstring with short description of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (2, 5), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "def coord_builder(X, Y):\n",
    "    \n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError(\"X and Y must be of equal length\")\n",
    "    \n",
    "    return [(x, y) for x, y in zip(X, Y)]\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [4, 5, 6]\n",
    "print(coord_builder(X, Y))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 2\n",
    "\n",
    "(1 PT) \n",
    "\n",
    "Call your `coord_builder()` function, passing in `X` and `Y`.  \n",
    "\n",
    "Then print the first ten tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 16), (2, 17), (3, 18), (4, 19), (5, 20), (6, 21), (7, 22), (8, 23), (9, 24), (10, 25)]\n"
     ]
    }
   ],
   "source": [
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "Y = [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "\n",
    "result = coord_builder(X, Y)\n",
    "\n",
    "print(result[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with AREA\n",
    "\n",
    "Next, we work the area column of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = firedata['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 2.17, 0.43, 0.0, 6.44, 54.29, 11.16, 0.0, 0.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3\n",
    "\n",
    "(1 PT)\n",
    "    \n",
    "Write code to print the minimum area and maximum area in a tuple\n",
    "`(min_value, max_value)`.\n",
    "\n",
    "Save `min_value` and `max_value` as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 1090.84)\n"
     ]
    }
   ],
   "source": [
    "areas = firedata['area']\n",
    "\n",
    "min_value = float(min(areas))\n",
    "max_value = float(max(areas))\n",
    "\n",
    "area_tuple = (min_value, max_value)\n",
    "\n",
    "print(area_tuple)  # Output will be (100.8, 300.4) based on the example list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "(2 PTS)\n",
    "\n",
    "Write a lambda function that applies the following function to $x$:   \n",
    "\n",
    "> $log_{10}(1 + x)$\n",
    "\n",
    "Return the rounded value to $2$ decimals.\n",
    "\n",
    "Assign the function to the variable `mylog10`.\n",
    "\n",
    "Then call the lambda function on `area` and print the last 10 values.  \n",
    "\n",
    "Hints: \n",
    "* Use the `log10` function from Python's [`math` module](https://docs.python.org/3/library/math.html). You'll need to import it.\n",
    "* Use a list comprehension to make the lambda function a one-liner.\n",
    "* To get the last members of a list, used negative offset slicing. See [the Python documentation on lists](https://docs.python.org/3/tutorial/introduction.html#lists) for a refresher on slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.5, 0.16, 0.0, 0.87, 1.74, 1.08, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Define the lambda function\n",
    "mylog10 = lambda x: round(math.log10(1 + x), 2)\n",
    "\n",
    "# Apply the lambda function to the 'area' column\n",
    "firedata['log_area'] = [mylog10(a) for a in firedata['area']]\n",
    "\n",
    "# Print the last 10 values of the transformed 'area' column\n",
    "print(firedata['log_area'][-10:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with MONTH\n",
    "\n",
    "The month column contains months of the year in abbreviated form &mdash; `jan` to `dec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = firedata['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mar', 'oct', 'oct', 'mar', 'mar', 'aug', 'aug', 'aug', 'sep', 'sep']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 5\n",
    "\n",
    "(1 PT)\n",
    "\n",
    "Create a function called `get_uniques()` that extracts the unique values from a list. \n",
    "* Do not use `set()` but instead use a **dictionary comprehension** to capture the unique names.\n",
    "* Hint: They keys in a dictionary are unique.\n",
    "* Hint: You do not need to count how many times a name appears in the source list.\n",
    "\n",
    "Then function should optionally return the list as sorted in ascending order. \n",
    "\n",
    "Then apply it to the `month` column of our data with sorting turned on. \n",
    "\n",
    "Then print the unique months.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apr', 'aug', 'dec', 'feb', 'jan', 'jul', 'jun', 'mar', 'may', 'nov', 'oct', 'sep']\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    for j, col in enumerate(row):\n",
    "        firedata[cols[j]].append(caster[dtypes[j]](col))\n",
    "\n",
    "def get_uniques(lst, sort=False):\n",
    "    \n",
    "    unique_dict = {item: None for item in lst}\n",
    "    unique_list = list(unique_dict.keys())\n",
    "    if sort:\n",
    "        unique_list.sort()\n",
    "    return unique_list\n",
    "\n",
    "unique_months = get_uniques(firedata['month'], sort=True)\n",
    "\n",
    "print(unique_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "(1 PT)\n",
    "\n",
    "Write a lambda function called `get_month_for_letter` that uses a list comprehension to select all months starting with a given letter\n",
    "from the list of unique month names you just crreated. \n",
    "\n",
    "The function should assume that the list of unique month names exists in the global context.\n",
    "\n",
    "The returned list should contain uppercase strings. \n",
    "\n",
    "Run and print the result with `a` as the paramter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['APR', 'AUG']\n"
     ]
    }
   ],
   "source": [
    "def get_uniques(lst, sort=False):\n",
    "    \n",
    "    unique_dict = {item: None for item in lst}\n",
    "    unique_list = list(unique_dict.keys())\n",
    "    if sort:\n",
    "        unique_list.sort()\n",
    "    return unique_list\n",
    "\n",
    "get_month_for_letter = lambda letter: [month.upper() for month in unique_months if month.startswith(letter)]\n",
    "\n",
    "result = get_month_for_letter('a')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with DMC\n",
    "DMC - DMC index from the FWI system: 1.1 to 291.3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmc = firedata['DMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.2, 35.4, 43.7, 33.3, 51.3, 85.3, 88.9, 145.4, 129.5, 88.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 7\n",
    "\n",
    "(2 PTS)\n",
    "\n",
    "Write a function called `bandpass_filter()` with these requirements:\n",
    "\n",
    "- Takes three inputs: \n",
    "  - A list of numbers `num_list`.\n",
    "  - An integer serving as a lower bound `lower_bound`.\n",
    "  - An integer serving as an upper bound `upper_bound`.\n",
    "- Returns a new array containing only the values from the original array which are greater than `lower_bound` and less than `upper_bound`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45 87 90 98 34 71 68 38]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_list = [12, 45, 87, 90, 98, 34, 4, 6, 71, 232, 548, 532, 68, 38]\n",
    "lower_bound = 12\n",
    "upper_bound = 232\n",
    "\n",
    "def bandpass_filter(num_list, lower_bound, upper_bound):\n",
    "    filtered_list = [i for i in num_list if lower_bound < i < upper_bound]\n",
    "    return np.array(filtered_list)\n",
    "\n",
    "filtered_array = bandpass_filter(num_list, lower_bound, upper_bound)\n",
    "print(filtered_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "(1 PT)\n",
    "\n",
    "Call `bandpass_filter()` passing `dmc` as the list, with `lower_bound=25` and `upper_bound=35`. \n",
    "\n",
    "Then print the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.2 33.3 32.8 27.9 27.4 25.7 33.3 33.3 30.7 33.3 25.7 25.7 25.7 32.8\n",
      " 27.2 27.8 26.4 25.4 25.4 25.4 25.4 26.7 25.4 27.5 28.  25.4 26.2 33.3\n",
      " 32.8 27.9 27.4 25.7 33.3 33.3 30.7 33.3 25.7 25.7 25.7 32.8 27.2 27.8\n",
      " 26.4 25.4 25.4 25.4 25.4 26.7 25.4 27.5 28.  25.4 26.2 33.3 32.8 27.9\n",
      " 27.4 25.7 33.3 33.3 30.7 33.3 25.7 25.7 25.7 32.8 27.2 27.8 26.4 25.4\n",
      " 25.4 25.4 25.4 26.7 25.4 27.5 28.  25.4]\n"
     ]
    }
   ],
   "source": [
    "dmc_list = firedata[\"DMC\"]\n",
    "lower_bound = 25\n",
    "upper_bound = 35\n",
    "\n",
    "dmc = bandpass_filter(dmc_list, lower_bound, upper_bound)\n",
    "print(dmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with FFMC\n",
    "FFMC - FFMC index from the FWI system: 18.7 to 96.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmc = firedata['FFMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86.2, 90.6, 90.6, 91.7, 89.3, 92.3, 92.3, 91.5, 91.0, 92.5]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffmc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 9\n",
    "\n",
    "(2 PTS)\n",
    "\n",
    "Write a lambda function `get_mean` that computes the mean $\\mu$ of a list of numbers.\n",
    "* The mean is jus the sum of a list of numeric values divided by the length of that list.\n",
    "\n",
    "Write another lambda function `get_ssd` that computes the squared deviation of a number.\n",
    "* The function takes two arguments, a number from a given list and the mean of the numbers in that list.\n",
    "* The function is meant to be used in a for-loop that iterates through a list.\n",
    "* The squared deviation of a list element $x_i$ is $(x_i - \\mu)^2$.\n",
    "\n",
    "Then write `get_sum_sq_err()` with these requirements:\n",
    "* Takes a numeric list as input.\n",
    "* Computes the mean $\\mu$ of the list using `get_mean`. \n",
    "* Computes the sum of squared deviations for the list using a list comprehension that applies `get_ssd`.\n",
    "* Returns the sum of squared deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mean = lambda lst: sum(lst) / len(lst)\n",
    "\n",
    "get_ssd = lambda x, mean: (x - mean) ** 2\n",
    "\n",
    "def get_sum_sq_err(num_list):\n",
    "    mean = get_mean(num_list)\n",
    "    sum_sq_err = sum([get_ssd(x, mean) for x in num_list])\n",
    "    return sum_sq_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 10\n",
    "\n",
    "(1 PT)\n",
    "\n",
    "Call `sum_sq_err()` passing `ffmc` as the list and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15723.357872340424\n"
     ]
    }
   ],
   "source": [
    "ffmc_list = firedata['FFMC']\n",
    "\n",
    "# Call the get_sum_sq_err function\n",
    "sum_sq_err = get_sum_sq_err(ffmc_list)\n",
    "\n",
    "# Print the result\n",
    "print(sum_sq_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
